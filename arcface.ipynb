{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /home/nikhil/Desktop/repo/KamleshThesis/env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras.layers as layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from deepface.basemodels.ArcFace import loadModel\n",
    "from deepface.commons import functions\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model=ArcFace\n",
    "ArcFace.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Contrastive Loss\n",
    "def contrastive_loss(y, preds, margin=1):\n",
    "    y = tf.cast(y, preds.dtype)\n",
    "    squaredPreds = K.square(preds)\n",
    "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance Layer\n",
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance\n",
    "    between the embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, compare):\n",
    "        sum_squared = K.sum(K.square(anchor - compare), axis=1, keepdims=True)\n",
    "        return K.sqrt(K.maximum(sum_squared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide input shape\n",
    "input_shape_x, input_shape_y = functions.find_input_shape(model)\n",
    "t_shape = (input_shape_x, input_shape_y, 3)\n",
    "\n",
    "anchor_input = layers.Input(name=\"anchor\", shape=t_shape)\n",
    "compare_input = layers.Input(name=\"compare\", shape=t_shape)\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    model(anchor_input),\n",
    "    model(compare_input),\n",
    ")\n",
    "\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\") (distances)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[anchor_input, compare_input], outputs=outputs,\n",
    "    name = \"ArcFace_Training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img_path, input_shape_y = input_shape_y, input_shape_x = input_shape_x, enforce_detection = True\n",
    "\t\t, detector_backend = 'opencv', align = True, normalization = 'base'):\n",
    "\t'''Returns Image when given the following details'''\n",
    "\t#detect and align\n",
    "\timg = functions.preprocess_face(img = img_path\n",
    "\t\t, target_size=(input_shape_y, input_shape_x)\n",
    "\t\t, enforce_detection = enforce_detection\n",
    "\t\t, detector_backend = detector_backend\n",
    "\t\t, align = align)\n",
    "\n",
    "\t#custom normalization\n",
    "\timg = functions.normalize_input(img = img, normalization = normalization)\n",
    "\treturn img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data directory paths\n",
    "data_folder = \"/home/nikhil/Desktop/repo/KamleshThesis/data/LFW/lfw/\"\n",
    "img_type = ['jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = os.listdir(data_folder)\n",
    "name_list = name_list[:300]\n",
    "face_labels = []\n",
    "face_images = []\n",
    "\n",
    "print(\"Processing \", len(name_list), \" Folders\\n\\n\")\n",
    "for fold in name_list:\n",
    "    per_path = os.path.join(data_folder, fold)\n",
    "    if os.path.isdir(per_path):\n",
    "        for img in os.listdir(per_path):\n",
    "            img_path = os.path.join(per_path, img)\n",
    "            if os.path.isfile(img_path) and img[-3:].lower() in img_type:\n",
    "                try:\n",
    "                    img_arr = get_img(img_path)\n",
    "                    face_labels.append(name_list.index(fold))\n",
    "                    face_images.append(img_arr)\n",
    "                except:\n",
    "                    print('Cannot load '+fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_len = len(face_images)\n",
    "if img_len == 1:\n",
    "    print(\"removing Extra\")\n",
    "    face_images = face_images[0]\n",
    "\n",
    "if len(face_images[0]) != input_shape_x:\n",
    "    for index, face in enumerate(face_images):\n",
    "        face_images[index] = face[0]\n",
    "\n",
    "if img_len == len(face_labels):\n",
    "    print('success')\n",
    "else:\n",
    "    print('Failiure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(face_images[0][0]))\n",
    "face_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate image pairs\n",
    "def generate_image_pairs(images, labels):\n",
    "    # Generate index for each label\n",
    "    unique_labels = np.unique(labels)\n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label,\n",
    "                                      [index for index, curr_label in enumerate(labels) if\n",
    "                                       label == curr_label])\n",
    "    \n",
    "    # Generate image pairs and labels\n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for index, image in enumerate(images):\n",
    "        pos_indices = label_wise_indices.get(labels[index])\n",
    "        pos_image = images[np.random.choice(pos_indices)]\n",
    "        pair_images.append((image, pos_image))\n",
    "        pair_labels.append(1)\n",
    "\n",
    "        neg_indices = np.where(labels != labels[index])\n",
    "        neg_image = images[np.random.choice(neg_indices[0])]\n",
    "        pair_images.append((image, neg_image))\n",
    "        pair_labels.append(0)\n",
    "        \n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dataset, labels_dataset = generate_image_pairs(face_images, face_labels)\n",
    "images_dataset, labels_dataset = shuffle(images_dataset, labels_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [images_dataset[:, 0, :], images_dataset[:, 1, :]], \n",
    "    labels_dataset,\n",
    "    epochs=10, \n",
    "    validation_split = 0.2, \n",
    "    batch_size = 64, \n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            'model.hdf5',\n",
    "            verbose=1, \n",
    "            save_best_only=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.legend([\"Loss\", \"Validation Loss\", \"Accuracy\", \"Validation Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_visualize(images, n = 5):\n",
    "    \"\"\" Visualize a few images \"\"\"\n",
    "\n",
    "    def show(ax, image):\n",
    "        ax.imshow(image)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 9)) \n",
    "    axs = fig.subplots(1, n)\n",
    "    for i in range(n):\n",
    "        show(axs[i], images[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = [0, 1, 2, 3, 4]\n",
    "test_index = random.sample(range(0, 50), 1)[0]\n",
    "test_image = face_images[test_index]\n",
    "\n",
    "compare_images = []\n",
    "for i in range(5):\n",
    "    index = random.sample(range(i * 10, (i + 1) * 10), 1)[0]\n",
    "    image = face_images[index]\n",
    "    compare_images.append(image)\n",
    "plt.imshow(test_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
